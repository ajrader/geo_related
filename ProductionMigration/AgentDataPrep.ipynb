{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd C:\\Users\\KESJ\\Documents\\projects\\Production Migration Project\\csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years=['0405','0506','0607','0708','0809','0910','1011']\n",
    "years[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years=['0405','0506','0607','0708','0809','0910','1011']\n",
    "\n",
    "\n",
    "for y in years[6:]:\n",
    "    print \"Starting with \",y\n",
    "    inflow = pd.read_csv(\"countyinflow\"+y+\".csv\",\n",
    "                         dtype={'State_Code_Dest':np.str,\n",
    "                                'County_Code_Dest':np.str,\n",
    "                                'State_Code_Origin':np.str,\n",
    "                                'County_Code_Origin':np.str,\n",
    "                                'State_Abbrv':np.str,\n",
    "                                'County_Name':np.str})\n",
    "\n",
    "    outflow = pd.read_csv(\"countyoutflow\"+y+\".csv\",\n",
    "                         dtype={'State_Code_Dest':np.str,\n",
    "                                'County_Code_Dest':np.str,\n",
    "                                'State_Code_Origin':np.str,\n",
    "                                'County_Code_Origin':np.str,\n",
    "                                'State_Abbrv':np.str,\n",
    "                                'County_Name':np.str})\n",
    "\n",
    "\n",
    "    fips = get_all_fips(inflow)\n",
    "\n",
    "    df = net_df()\n",
    "\n",
    "    for i,f in enumerate(fips):\n",
    "        print y,'-',i,'/',len(fips),':',f\n",
    "        df = df.append(get_net_change_for_fips(inflow,outflow,f[0],f[1]), ignore_index=True)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    df.sort([df.columns[0],df.columns[1]],inplace=True,ascending=True)\n",
    "    df.to_csv(\"countynetflow2\"+y+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now dealing with 0910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years=['0405','0506','0607','0708','0809','0910','1011']\n",
    "\n",
    "\n",
    "y = years[5]\n",
    "print \"Starting with \",y\n",
    "inflow = pd.read_csv(\"countyinflow\"+y+\".csv\",\n",
    "                         dtype={'State_Code_Dest':np.str,\n",
    "                                'County_Code_Dest':np.str,\n",
    "                                'State_Code_Origin':np.str,\n",
    "                                'County_Code_Origin':np.str,\n",
    "                                'State_Abbrv':np.str,\n",
    "                                'County_Name':np.str})\n",
    "inflow[['State_Code_Dest','State_Code_Origin']]=inflow[['State_Code_Dest','State_Code_Origin']].applymap(lambda x: prependZeros(x,2))\n",
    "inflow[['County_Code_Origin','County_Code_Dest']]=inflow[['County_Code_Origin','County_Code_Dest']].applymap(lambda x: prependZeros(x))\n",
    "\n",
    "outflow = pd.read_csv(\"countyoutflow\"+y+\".csv\",\n",
    "                         dtype={'State_Code_Dest':np.str,\n",
    "                                'County_Code_Dest':np.str,\n",
    "                                'State_Code_Origin':np.str,\n",
    "                                'County_Code_Origin':np.str,\n",
    "                                'State_Abbrv':np.str,\n",
    "                                'County_Name':np.str})\n",
    "\n",
    "outflow[['County_Code_Origin','County_Code_Dest']]=outflow[['County_Code_Origin','County_Code_Dest']].applymap(lambda x: prependZeros(x))\n",
    "\n",
    "fips = get_all_fips(inflow)\n",
    "\n",
    "df = net_df()\n",
    "\n",
    "for i,f in enumerate(fips):\n",
    "    print y,'-',i,'/',len(fips),':',f\n",
    "    df = df.append(get_net_change_for_fips(inflow,outflow,f[0],f[1]), ignore_index=True)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "df.sort([df.columns[0],df.columns[1]],inplace=True,ascending=True)\n",
    "df.to_csv(\"countynetflow2\"+y+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inflow needs the county_code_origin prepended by '00' or '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prependZeros(inValue,desLen=3):\n",
    "    while (len(inValue)<desLen):\n",
    "        inValue='0'+inValue\n",
    "    return inValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prependZeros('13',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fips = get_all_fips(inflow)\n",
    "\n",
    "df = net_df()\n",
    "\n",
    "for i,f in enumerate(fips):\n",
    "    print y,'-',i,'/',len(fips),':',f\n",
    "    df = df.append(get_net_change_for_fips(inflow,outflow,f[0],f[1]), ignore_index=True)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "df.sort([df.columns[0],df.columns[1]],inplace=True,ascending=True)\n",
    "df.to_csv(\"countynetflow2\"+y+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a for a in outflow['County_Code_Origin'].unique() if len(a)!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, f in enumerate(fips):\n",
    "    print i, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#AJ Rader --> putting all the PIF data (from pcadss together)\n",
    "desire is to create a single dataframe that has initial PIF values for each year, final values for each year and change over that year.\n",
    "the amounts reported in PIF20xxYY correspond to the total number in force at the end of month YY and year 20xx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearPeriods = ['0405','0506','0607','0708','0809','0910','1011','1112']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in yearPeriods:\n",
    "    print year\n",
    "    pdf = pd.read_csv('pifchange'+year+'.csv',\n",
    "                      dtype={'FIPS_CD':str, 'COUNTY':np.str,\n",
    "                            'STATE':np.str, 'POSTL_ST_CD':np.str})\n",
    "    pdf.drop('PIF_NET_CHANGE',1,inplace=True) #drop net change column\n",
    "    #print np.shape(pdf), pdf.columns[:2]\n",
    "    if int(year)== 405:\n",
    "        pif_df2 = pdf.copy() #mv initial to 2nd version\n",
    "    else:\n",
    "        pif_df2 = pd.merge(pif_df2,pdf,on='FIPS_CD')\n",
    "    \n",
    "print \"this dataframe has the following dimensions\", np.shape(pif_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify repeat columns and remove them from the dataframe\n",
    "dupColumn = []\n",
    "#dupColumnY = []\n",
    "#dColumnBase = []\n",
    "nrows = len(pif_df2)\n",
    "for c in pif_df2.columns:\n",
    "    if c.endswith('_x'):\n",
    "        dupColumn.append(c)\n",
    "        # check if they match each other (sanity check)\n",
    "        c2 = c[:-2]+\"_y\"\n",
    "        #dupColumnY.append(c2)\n",
    "        #dColumnBase.append(c[:-2])\n",
    "        print \"Do columns {0} and {1} match? {2}\".format(c,c2,sum((pif_df2[c]-pif_df2[c2])==0)==nrows)\n",
    "\n",
    "ydupCols = [c[:-2]+'_y' for c in dupColumn]\n",
    "dupColDict = {}\n",
    "for c in dupColumn:\n",
    "    dupColDict[c]= c[:-2]\n",
    "#dColumnBase = [c[:-2] for c in dupColumn]\n",
    "pif_df2.drop(ydupCols,1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pif_df2.rename(columns=dupColDict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pif_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SAVE full dataset\n",
    "pif_df2.to_csv('pif_200410to201210.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pif_time = pif_df2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a dictionary out of the fipsCodes for column headings\n",
    "fipsCodes = pif_time.loc['FIPS_CD',:].values\n",
    "fipsDict = {}\n",
    "for i in xrange(0,len(fipsCodes)):\n",
    "    fipsDict[i]=fipsCodes[i]\n",
    "\n",
    "pif_time.drop('FIPS_CD',0,inplace=True)\n",
    "pif_time.rename(columns=fipsDict,inplace=True)\n",
    "#.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.datetime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert PIF20xxYY to date\n",
    "date = pd.to_datetime([a[3:] for a in pif_time.index],format='%Y%m')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pif_time.index = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearEnd = pif_time.resample('AS-JAN',how='last')\n",
    "wrongindex = yearEnd.index\n",
    "#newindex = wrongindex.year+1\n",
    "#newindex\n",
    "#yearEnd.index = pd.to_datetime(['01/01/2005','01/01/2006')\n",
    "#yearStart = pif_time.resample('AS-JAN',how='first')\n",
    "                  #, how='diff')\n",
    "#yearEnd.index = pd.to_datetime(newindex,format='%Y')\n",
    "#yearEnd['01001'].plot(ms='o',ls='--',color='midnightblue')\n",
    "yearEnd.diff()['01001'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AJR 11.21.2014\n",
    "\n",
    "# Data Prep for ...\n",
    "##1. Agent AFO listing\n",
    "##2. mapping zipcodes to FIPSCDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('../../projects/Production Migration Project/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the zipCode database\n",
    "zipDF = pd.read_csv('zip_code_database.csv',dtype={'zip':np.str})\n",
    "zipDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF.decommissioned.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF.county.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF.estimated_population.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(zipDF.county.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print zipDF.state.unique(), len(zipDF.state.unique())\n",
    "nonUSstateCodes = ['AA','AE','AP','AS','FM','GU','MH','MP','PR','PW','VI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a in np.sort(zipDF[~zipDF['state'].isin(nonUSstateCodes)].state.unique()):\n",
    "    print a, zipDF[zipDF.state == a].timezone.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sort(zipDF[~zipDF['state'].isin(nonUSstateCodes)].state.unique()), len(zipDF[~zipDF['state'].isin(nonUSstateCodes)].state.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove zip codes for 'states' outside the US: i.e.\n",
    "zipDF = zipDF[~zipDF['state'].isin(nonUSstateCodes)]\n",
    "zipDF.index = np.arange(0,len(zipDF))\n",
    "zipDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list of missing zipCode Counties\n",
    "print len(zipDF[zipDF['county'].isnull()])\n",
    "zipDF[zipDF['county'].isnull()]\n",
    "# map these to nearbly county\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## fix these mising counties in zipDF\n",
    "zipCountyMissing = zipDF[zipDF['county'].isnull()]\n",
    "print len(zipCountyMissing.primary_city.unique()), len(zipCountyMissing.state.unique())\n",
    "#for line in zipDF[zipDF['county'].isnull()]:\n",
    "#    print line\n",
    "zipCountyMissing[['zip','primary_city','state','decommissioned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipCountyMissing.primary_city.unique(), zipCountyMissing.zip.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a dictionary for these 'bad' cases\n",
    "# pulled from looking up on http://www.zip-codes.com/zip-code/22350/zip-code-22350.asp \n",
    "#I should map from zip to county too?\n",
    "missingCountyFixDict = {}\n",
    "missingCountyFixDict['New York']='New York County'\n",
    "missingCountyFixDict['Pittsburgh']='Allegheny County'\n",
    "missingCountyFixDict['Washington'] ='District of Columbia'\n",
    "missingCountyFixDict['Alexandria'] ='Alexandria City'\n",
    "missingCountyFixDict['Woodberry Forest'] ='Madison County'\n",
    "missingCountyFixDict['High Shoals'] ='Oconee County'\n",
    "missingCountyFixDict['Rhodhiss'] = 'Caldwell County'\n",
    "missingCountyFixDict['Kennesaw'] ='Cobb County'\n",
    "missingCountyFixDict['Miami']='Miami-Dade County'\n",
    "missingCountyFixDict['Elbridge'] ='None'\n",
    "missingCountyFixDict['Tougaloo'] ='Hinds County'\n",
    "missingCountyFixDict['Des Moines']='Polk County'\n",
    "missingCountyFixDict['Freeman Spur']='Williamson County'\n",
    "missingCountyFixDict['Farmerville']='Union Parish'\n",
    "missingCountyFixDict['Hinton']='Caddo County' #judgement call based upon wikipedia: spans both Caddo and Canadian Counties\n",
    "missingCountyFixDict['Ardmore']='Carter County'\n",
    "missingCountyFixDict['Frisco']='Collin County' #judgement call based upon wikipedia: majority seems to be here rather than Denton County\n",
    "missingCountyFixDict['Stonington']='None'\n",
    "missingCountyFixDict['Salt Lake City']='Salt Lake County'\n",
    "\n",
    "missingCountyFixDict['Kings Canyon National Pk'] = 'Tulare County'\n",
    "missingCountyFixDict['Springfield']='Lane County'\n",
    "missingCountyFixDict['Mill Creek']='Snohomish County'\n",
    "missingCountyFixDict['Seattle']= 'King County'\n",
    "missingCountyFixDict['Wasilla'] = 'Matanuska-Susitna Borough'\n",
    "#'New York', 'Pittsburgh', 'Washington', 'Alexandria',\n",
    "#       'Woodberry Forest', 'Rhodhiss', 'High Shoals', 'Kennesaw', 'Miami',\n",
    "#       'Elbridge', 'Tougaloo', 'Des Moines', 'Freeman Spur', 'Farmerville',\n",
    "#       'Hinton', 'Ardmore', 'Frisco', 'Stonington', 'Salt Lake City',\n",
    "#       'Kings Canyon National Pk', 'Springfield', 'Mill Creek', 'Seattle',\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for city,state in zipCountyMissing[['primary_city','state',]].values:\n",
    "    print city, state\n",
    "    countyResults = zipDF[(zipDF.primary_city == city) & (zipDF.state == state)].county.unique()\n",
    "    print countyResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(missingCountyFixDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF.ix[zipCountyMissing.index]['county'] =zipDF.ix[zipCountyMissing.index].primary_city.apply(lambda x: missingCountyFixDict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF.loc[zipDF['county'].isnull(),'county'] = zipDF[zipDF['county'].isnull()].primary_city.apply(lambda x: missingCountyFixDict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF.to_csv('us_zip_cod_listing1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(zipDF.county.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fipsCountyList.County.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsCountyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fipsCountyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load file to map county name to FIPS code\n",
    "nflow1011 = pd.read_csv('countynetflow_1011.csv',dtype={'State_Code':np.str,\n",
    "                                'County_Code':np.str,\n",
    "                                'Code1':np.str,\n",
    "                                'Code2':np.str,\n",
    "                                'Abbrv':np.str,\n",
    "                                'Name':np.str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nflow1011.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "nflow1011.drop(['Unnamed: 0','Return_In', 'Return_Out', 'Return_Net', 'Exmpt_In', u'Exmpt_Out', u'Exmpt_Net', u'Aggr_AGI_In', u'Aggr_AGI_Out', u'Aggr_AGI_Net'],1,inplace=True)\n",
    "# assign FIPS_CD\n",
    "nflow1011['FIPS_CD'] = nflow1011.State_Code + nflow1011.County_Code\n",
    "# assign ITEM_CD (i.e. migrants or non-migrants, etc.) --> \n",
    "# I just want the  non_migrants (ITEM_CD == FIPS_CD) \n",
    "nflow1011['ITEM_CD'] = nflow1011.Code1 + nflow1011.Code2\n",
    "\n",
    "# keep only cases where 'ITEM_CD' == FIPS_CD\n",
    "print \"keep only {0} FIPSCDS\".format(len(nflow1011[nflow1011['ITEM_CD']==nflow1011['FIPS_CD']]))\n",
    "fipsList = nflow1011[nflow1011['ITEM_CD']==nflow1011['FIPS_CD']].copy()\n",
    "fipsList.index = np.arange(0,len(fipsList))\n",
    "fipsList.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create a dictionary that maps FIPS_CD to Name --> remove the Non-Migrants part\n",
    "fipsList['County'] = fipsList.Name.apply(lambda x: x.split(' Non-Migrants')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split on ' '\n",
    "def countyNameNorming(x):\n",
    "    nmissing = 0\n",
    "    y = x.split(' ') #assign y the space split county name#\n",
    "    # look at the last element of this list\n",
    "    # standard names are \"County, Borough, and Parish\"\n",
    "    stdNames = ['County','Borough','Parish','city']\n",
    "    if y[-1] in stdNames:\n",
    "        return x #don't change\n",
    "    else:\n",
    "        if y[-1].startswith('ci'):# =='City':# or y[-1] == 'city':\n",
    "            y[-1] = 'city' # works for cities in virginia\n",
    "            #print \"\\t\", x\n",
    "        elif y[-1].startswith('Co'):\n",
    "            y[-1] = 'County'\n",
    "        elif y[-1].startswith('Bo'):\n",
    "            y[-1] = 'Borough'\n",
    "        elif y[-1].startswith('Pa'):\n",
    "            y[-1] = 'Parish'#\n",
    "        elif y[-1].startswith('Are'):\n",
    "            #print x, y[-1]\n",
    "            y[-1] = 'Area'\n",
    "        elif y[-1].startswith('Ce'):\n",
    "            y[-1] = 'Census Area'\n",
    "        elif y[-1].startswith('c'):\n",
    "            y[-1] = 'city'\n",
    "            #y[-1] = 'County' # assumes a county\n",
    "            print x, y[-1]\n",
    "            #print x, y[-1]\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            nmissing+=1\n",
    "            print \"\\t unknown term\\t\", x\n",
    "            \n",
    "            \n",
    "        z=' '.join(y)\n",
    "        return z\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsList['County'] = fipsList['County'].apply(lambda x: countyNameNorming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fipsList[fipsList['Abbrv']=='AK']['County'].unique()), len(zipDF[zipDF.state=='AK'].county.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsList[fipsList['Abbrv']=='AK']['County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "akset1 = set(zipDF[zipDF.state=='AK'].county.unique())\n",
    "akset2 = set(fipsList[fipsList['Abbrv']=='AK']['County'].unique())\n",
    "akset1.difference(akset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF[zipDF.state=='AK' ][['zip','county','primary_city','decommissioned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "akset2.difference(akset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an fips dictonary of changes\n",
    "fipsCountyNamesDict = {}\n",
    "fipsCountyNamesDict['Aleutians East'] = 'Aleutians East Borough'\n",
    "fipsCountyNamesDict['Aleutians West'] = 'Aleutians West Census Area'\n",
    "fipsCountyNamesDict['Anchorage Munic'] = '',\n",
    " 'Bethel Census A',\n",
    " 'Fairbanks North',\n",
    " 'Hoonah Angoon C',\n",
    " 'Juneau City and',\n",
    " 'Kenai Peninsula',\n",
    " 'Ketchikan Gatew',\n",
    " 'Kodiak Island B',\n",
    " 'Lake and Penins',\n",
    " 'Matanuska Susit',\n",
    "fipsCountyNamesDict['Northwest Arcti'] = 'Northwest Arctic Borough'\n",
    "fipsCountyNamesDict['Petersburg Census Area'] = 'Petersburg Borough'\n",
    " 'Prince of Wales',\n",
    " 'Sitka City and',\n",
    " 'Skagway Municip',\n",
    " 'Southeast Fairb',\n",
    " 'Valdez County',\n",
    " 'Wrangell City a',\n",
    " 'Wrangell Peters',\n",
    " 'Yakutat City an',\n",
    " 'Yukon Koyukuk C']\n",
    "    \n",
    "    \n",
    " \n",
    " 'Anchorage Borough',\n",
    " 'Bethel Census Area',\n",
    " 'City and Borough of Juneau',\n",
    " 'Fairbanks North Star Borough',\n",
    " 'Hoonah-Angoon Borough',\n",
    " 'Juneau Borough',\n",
    " 'Kenai Peninsula Borough',\n",
    " 'Ketchikan Gateway Borough',\n",
    " 'Kodiak Island Borough',\n",
    " 'Lake and Peninsula Borough',\n",
    " 'Matanuska-Susitna Borough',\n",
    " 'Municipality of Anchorage',\n",
    " ,\n",
    " \n",
    " 'Prince of Wales-Outer Ketchikan Borough',\n",
    " 'Sitka Borough',\n",
    " 'Skagway Borough',\n",
    " 'Southeast Fairbanks Census Area',\n",
    " 'Valdez-Cordova Census Area',\n",
    " 'Wrangell Borough',\n",
    " 'Yakutat Borough',\n",
    " 'Yukon-Koyukuk Census Area'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsList[fipsList.Abbrv=='AK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in zipDF[zipDF.state =='AK'].county.unique() if str(x).startswith('Peters')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF[zipDF.state =='AK'].county.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF[zipDF.county=='Prince of Wales-Outer Ketchikan Borough']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "# load the fips-code listing from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsCountyList = pd.read_csv('fipsListing_1.csv',dtype={'INCITS':np.str})\n",
    "# fix the INCITS CODES to prepend 0 if smaller\n",
    "fipsCountyList['INCITS']=fipsCountyList['INCITS'].apply(lambda x: prependZeros(x,5))\n",
    "fipsCountyList.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsCountyList[fipsCountyList.State == 'Alaska']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "badcases = [c for c in fipsCountyList.County if c.endswith(']')]\n",
    "for b in badcases:\n",
    "    match = re.match('(.+)(\\[\\d+\\])',b)\n",
    "    if match:\n",
    "        print match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fipsCountyList.State.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "state2abbrv = {}\n",
    "listOfstateNames = fipsCountyList.State.unique()\n",
    "abbrv = [ 'AL','AK','AZ','AR',\n",
    " 'CA', 'CO', 'CT', 'DE', 'DC',\n",
    " 'FL', 'GA', 'HI', 'ID','IL','IN','IA',\n",
    " 'KS', 'KY', 'LA',\n",
    " 'ME','MD','MA','MI', 'MN',  'MS','MO', 'MT',\n",
    " 'NE', 'NV',  'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', \n",
    " 'OH', 'OK', 'OR', 'PA',\n",
    " 'RI', 'SC', 'SD',\n",
    " 'TN', 'TX', 'UT', 'VT', 'VA',\n",
    " 'WA', 'WV', 'WI', 'WY']\n",
    "for i in xrange(0,len(listOfstateNames)):\n",
    "    state2abbrv[listOfstateNames[i]]=abbrv[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# append stAbbrev to fipsCountyList\n",
    "fipsCountyList['stAbbv'] = [state2abbrv[x] for x in fipsCountyList.State.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def fix_countyAnnotations(x):\n",
    "#for c in fipsCountyList.County:\n",
    "    match = re.match('(.*)(\\[\\d*\\])',x)\n",
    "    if match:\n",
    "        return match.group(1)#[:-1]\n",
    "    else:\n",
    "        return x\n",
    "        #print c, match.group(1)[:-1]\n",
    "        \n",
    "fipsCountyList['County'] = fipsCountyList.County.apply(lambda x: fix_countyAnnotations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF[zipDF.primary_city=='San Francisco'].county.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hasCommas = [c for c in fipsCountyList.County if ',' in c]\n",
    "len(hasCommas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hasCommas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fixCandBof(x):\n",
    "    y = x.split(',')\n",
    "    if len(y)>1:\n",
    "        print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsCountyList.loc[67:95,'County'].apply(lambda x: fixCandBof(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF[zipDF.state == 'AK']['county'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsCountyList.County.str.replace('?','-',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a for a in fipsCountyList.loc[67:90,'County'] if '?' in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsCountyList.loc[67:95,'County']#.str.replace('?', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF[zipDF.primary_city=='Anchorage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[c for c in fipsCountyList.County if ',' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endswithCity = [c for c in fipsCountyList.County if c.endswith(', City of')]\n",
    "for city in endswithCity:\n",
    "    rename = city.split(',')\n",
    "    newName = rename[0]+' City'\n",
    "    rowID = fipsCountyList[fipsCountyList.County==city].index \n",
    "    fipsCountyList.loc[rowID,'County']=newName\n",
    "\n",
    "[c for c in fipsCountyList.County if c.endswith(', City of')]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsCountyList['stcnty']=fipsCountyList['stAbbv']+fipsCountyList['County']\n",
    "fips_STcounty = fipsCountyList.stcnty.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF['stcnty']=zipDF['state']+zipDF['county']\n",
    "zip_code_STcounty = zipDF['stcnty'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''.join(hasDot[2].split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF[zipDF['county'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hasDot2 = [c for c in zipDF.county if '.' in c]\n",
    "for c in hasDot2:\n",
    "    rename = ''.join(c.split('.'))\n",
    "    rowID = zipDF[zipDF.county==c].index \n",
    "    zipDF.loc[rowID,'county']=rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hasDot = [c for c in fipsCountyList.County if '.' in c]\n",
    "for c in hasDot:\n",
    "    rename = ''.join(c.split('.'))\n",
    "    rowID = fipsCountyList[fipsCountyList.County==c].index \n",
    "    fipsCountyList.loc[rowID,'County']=rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print len(zip_code_STcounty), len(fips_STcounty)\n",
    "#import re\n",
    "#map(lambda x: if re.match('(.*)\\s team:', x, re.IGNORECASE).group(1)[:-1],fipsCountyList.County else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(zip_code_STcounty).difference(set(fips_STcounty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fipsCountyList[fipsCountyList.stAbbv=='WI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len([x for x in fipsCountyList.County.unique() if x.endswith('Parish')])\n",
    "print len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fipsList[fipsList['Abbrv']=='AK']['County'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nmissing = 0\n",
    "fipsList['County'].apply(lambda x: countyNameNorming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len([x for x in fipsList['County'].values if x.split(' ')[-1].startswith('Pa')])\n",
    "print len(fipsList[fipsList['Abbrv']=='LA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in fipsList[fipsList['Abbrv']=='LA'].County if not (x.split(' ')[-1].endswith('P'))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data from pcadss and from ADM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentDF = pd.read_csv('agent/agentAFOfull.tsv',delimiter='\\t') # this is the data from PCADSS\n",
    "agentDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentDF.AGENT_STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load and mask data from ADM\n",
    "agentList = pd.read_csv('agent/agentInfo.csv', dtype={'CUR PLAN CODE':np.str, 'MOA ST-AGT-CD':np.str,'PRIMARY ST-AGT-CD.1':np.str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(agentList.SSN.unique()), len(agentList['AWARDS ID'].unique())\n",
    "#agentList.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "#create a hash keytable for the SSN and remove them from the dataset\n",
    "alhash= {}\n",
    "hstart = 20\n",
    "for v in agentList.SSN.unique():\n",
    "    alhash[v]=hstart+1\n",
    "    hstart+=1\n",
    "    \n",
    "# assign the agentList SSN to unique ids\n",
    "agentList['uniqID'] = agentList['SSN'].apply(lambda x: alhash[x])\n",
    "# drop the SSN values\n",
    "agentList.drop('SSN',axis=1,inplace=True)\n",
    "# create a short 5-digit zip code value\n",
    "agentList['zip5'] = agentList['OFFICE ZIP'].apply(lambda x: x[:5])\n",
    "\n",
    "print np.shape(agentList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove Canadian cases:\n",
    "nCanadian = len(agentList[agentList['GEO MARKET AREA']=='Canada'])\n",
    "canadianState1 = agentList[agentList['GEO MARKET AREA']=='Canada']['STATE.1'].unique()\n",
    "print nCanadian,\" Canadian agents for these provinces will be dropped:\", canadianState1\n",
    "agentList = agentList[~agentList['STATE.1'].isin(canadianState1)]\n",
    "print np.shape(agentList)\n",
    "#agentList.replace('STATE.1','XX')#drop('STATE.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList['GEO MARKET AREA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## things to do:\n",
    "1. assign the fipsCode to each agent row\n",
    "2. get the dates when an agent is active so I can do a simple groupby-count to get number of active "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList[[u'APPOINT DATE', u'FIRST APPOINT DATE', u'STATUS','TERMINATION DATE','zip5']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many unique zip5 codes?\n",
    "len(agentList['zip5'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agentList['STATE.1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList.to_csv('../../../agentInfo2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list which agents have mulitple lines\n",
    "aLidsVC = agentList.uniqID.value_counts()\n",
    "aLidsVC[aLidsVC > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del alhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList[agentList.uniqID==15143][['NAME','CODE',u'APPOINT DATE', u'FIRST APPOINT DATE', u'STATUS','TERMINATION DATE','zip5','STATE.1','REASON TERMINATED']]#['STATE.1','OFFICE ZIP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check if there are enough 'terminations for these duplicate list of ids\n",
    "dupIds = [c for c in aLidsVC.index]\n",
    "dupIds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList['APPOINT DATE'].min(), agentList['FIRST APPOINT DATE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dec2014 = pd.to_datetime('01DEC2014')\n",
    "firstDate = pd.to_datetime(agentList['APPOINT DATE'].min())\n",
    "firstDate, dec2014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dateSpan = pd.date_range(start ='4/1/1929',end='12/1/2014',freq='M')\n",
    "len(dateSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(agentList.zip5.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[c for c in zipDF.county if c.endswith('Parish')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a zip to county Mapping\n",
    "zipToCounty = {}\n",
    "for z in zipDF.zip:#.ix[:10]:\n",
    "    #print z, zipDF[zipDF.zip == z].county\n",
    "    zipDF[z] = zipDF[zipDF.zip == z].county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def activeCount(x,t):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for id in dupIds[:10]:\n",
    "    print id\n",
    "    print \"----------------------\"\n",
    "    print agentList[agentList.uniqID==id][['NAME','CODE',u'APPOINT DATE', u'FIRST APPOINT DATE', u'STATUS','TERMINATION DATE','zip5','STATE.1','REASON TERMINATED']]#['STATE.1','OFFICE ZIP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alIDtermCD = agentList.groupby('uniqID')['REASON TERMINATED'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vclisting_byID = alIDtermCD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(vclisting_byID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zcheck = agentList[(agentList['STATE.1']=='AK') & (agentList['TERMINATION DATE'].isnull())]['zip5'].values\n",
    "zcheck2 = agentList[agentList['STATE.1']=='AK']['zip5'].unique()\n",
    "len(zcheck2), len(zcheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for z in zcheck2:\n",
    "    print zipDF[zipDF.zip==z]['county'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zlist = agentList['zip5'].unique()\n",
    "print len(zlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(zipDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zzlist = zipDF[zipDF.zip.isin(zlist)].zip.unique()\n",
    "print len(zzlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extrazips_fromADM = list(set(zlist).difference(set(zzlist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList[agentList.zip5.isin(extrazips_fromADM)][['STATE.1','NAME','TERMINATION DATE','zip5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList[(agentList.zip5.isin(extrazips_fromADM)) & (pd.to_datetime(agentList['TERMINATION DATE']) >pd.to_datetime('01JAN2003'))][['STATE.1','NAME','TERMINATION DATE','zip5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList.ix[25284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dateutil.parser.parse(agentList.loc[35139,'TERMINATION DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(agentList.loc[35139,'TERMINATION DATE'],format='%d%M%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipDF[zipDF.zip=='97003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reread from new file\n",
    "aa = pd.read_csv('../../../agentInfo2.csv', dtype={'CUR PLAN CODE':np.str, 'MOA ST-AGT-CD':np.str,'PRIMARY ST-AGT-CD.1':np.str,'zip5':np.str})#, parse_dates = dateCols)\n",
    "#for c in aa.columns:\n",
    "#    if 'DATE' in c:\n",
    "#        print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dateCols = []\n",
    "for c in aa.columns:\n",
    "    if 'DATE' in c:\n",
    "        dateCols.append(c)\n",
    "        \n",
    "dateCols.remove('EARLY NOTIFICATION PROGRAM DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList['APPOINT DATE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_datetime('01SEP1958',format='%d%b%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa[dateCols] = aa[dateCols].applymap(lambda x: pd.to_datetime(x,format='%d%b%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jan2002start = pd.to_datetime('31DEC2001',format='%d%b%Y')\n",
    "len(aa[aa['TERMINATION DATE'] < jan2002start])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList[(agentList.zip5.isin(extrazips_fromADM)) & (pd.to_datetime(agentList['TERMINATION DATE'],format='%d%b%Y') >pd.to_datetime('01JAN2002',format='%d%b%Y'))][['STATE.1','NAME','TERMINATION DATE','zip5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa[aa['TERMINATION DATE'].isnull()][['NAME','TERMINATION DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z91910 = aa[aa.zip5=='91910']\n",
    "#aa[(aa.zip5 == 91910) & (aa['TERMINATION DATE'] > pd.to_datetime('12/31/2009')) & (aa['APPOINT DATE'] < pd.to_datetime('01/01/2010'))][['STATE.1','NAME','TERMINATION DATE','zip5']]\n",
    "len(z91910)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isActive(df,date,today=pd.to_datetime('12-31-2020')):\n",
    "    #print sum(df['TERMINATION DATE'].isnull())\n",
    "    # replace null times with today\n",
    "    df['TERMINATION DATE'].fillna(today,inplace=True)\n",
    "    #print sum(df['TERMINATION DATE'].isnull())\n",
    "    nactive= len(df[(df['APPOINT DATE'] <= date) & (df['TERMINATION DATE']>date)])\n",
    "    #print nactive\n",
    "    return nactive\n",
    "    #print len(df1)\n",
    "    #print df1[['NAME','APPOINT DATE','TERMINATION DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isActive(z91910,pd.to_datetime('08-01-1995'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z91910[['NAME','APPOINT DATE','TERMINATION DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atemp = aa[aa['STATE.1']=='ME']\n",
    "len(atemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList[agentList['STATE.1']=='ME'].zip5.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtZipDF = pd.DataFrame(columns=['zipCode'])\n",
    "#State_Code','County_Code',\n",
    "#      'Code1','Code2',\n",
    "#      'Abbrv','Name',\n",
    "#      'Return_In','Return_Out','Return_Net',\n",
    "#      'Exmpt_In','Exmpt_Out','Exmpt_Net',\n",
    "#      'Aggr_AGI_In','Aggr_AGI_Out','Aggr_AGI_Net'])\n",
    "#    return df\n",
    "for z,df in atemp.groupby('zip5'):\n",
    "    #agtZipDF = pd.DataFrame(columns=['zipCode'])\n",
    "    print z, len(df), isActive(df,pd.to_datetime('08-01-2001'))\n",
    "    print \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['TERMINATION DATE','APPOINT DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dateSpan[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dateSpan[-12], z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtActive = pd.DataFrame(columns=[z])\n",
    "agtActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = '91910'\n",
    "for t in dateSpan:\n",
    "    agtActive.loc[t,z] = isActive(z91910,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtActive['91910'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(agtActive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtActive.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtActive.loc[dateSpan[-30:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearSpan1 = pd.date_range(start ='1/1/1999',end='1/1/2015',freq='A')\n",
    "len(yearSpan1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearSpan1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t in yearSpan1:\n",
    "    print t, isActive(z91910,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa.zip5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YrlyAgtActive = pd.DataFrame(columns=['03431'])\n",
    "for z,df in aa.groupby('zip5'):\n",
    "    print z\n",
    "    for t in yearSpan1:\n",
    "        YrlyAgtActive.loc[t,z]=isActive(df,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.shape(YrlyAgtActive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YrlyAgtActive[['03431','03110']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YrlyAgtActive.to_csv('yrlyActiveAgents_byZip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dateSpan1 =  pd.date_range(start ='1/1/1999',end='1/1/2015',freq='M')\n",
    "len(dateSpan1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MtlyAgtActive=pd.DataFrame(columns=['03110'])\n",
    "for z, df in aa.groupby('zip5'):\n",
    "    print z\n",
    "    for t in dateSpan1:\n",
    "        MtlyAgtActive.loc[t,z]=isActive(df,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_data_for_fips(df, fips_state, fips_county):\n",
    "    return df[np.array(df[[0]] == fips_state) & np.array(df[[1]]==fips_county)]\n",
    "\n",
    "def get_totals_for_fips(df, fips_state, fips_county):\n",
    "    ff = df[np.array(df[[0]] == fips_state) & np.array(df[[1]]==fips_county)]\n",
    "    return ff.select(lambda x: int(ff.loc[x,ff.columns[2]]) >= 96 or (ff.loc[x,ff.columns[2]] == ff.loc[x,ff.columns[0]] and ff.loc[x,ff.columns[3]] == ff.loc[x,ff.columns[1]])).sort([ff.columns[2],ff.columns[3]])\n",
    "\n",
    "def net_df():\n",
    "    df = pd.DataFrame(columns=['State_Code','County_Code',\n",
    "      'Code1','Code2',\n",
    "      'Abbrv','Name',\n",
    "      'Return_In','Return_Out','Return_Net',\n",
    "      'Exmpt_In','Exmpt_Out','Exmpt_Net',\n",
    "      'Aggr_AGI_In','Aggr_AGI_Out','Aggr_AGI_Net'])\n",
    "    return df\n",
    "\n",
    "def get_net_change_for_fips(in_df, out_df, fips_state, fips_county):\n",
    "    in_df = get_totals_for_fips(in_df, fips_state, fips_county).reset_index()\n",
    "    out_df = get_totals_for_fips(out_df, fips_state, fips_county).reset_index()\n",
    "    assert(np.all(np.array(in_df[[3,4]])==np.array(out_df[[3,4]])))\n",
    "    \n",
    "    df = net_df()\n",
    "    df[['State_Code','County_Code',\n",
    "      'Code1','Code2',\n",
    "      'Abbrv','Name']] = in_df[['State_Code_Dest','County_Code_Dest',\n",
    "                                              'State_Code_Origin','County_Code_Origin',\n",
    "                                              'State_Abbrv','County_Name']]\n",
    "    #df['County_Code'] = in_df['County_Code_Dest']\n",
    "    #State_Code_Origin\tCounty_Code_Origin\tState_Abbrv\tCounty_Name\n",
    "    \n",
    "    df['Return_In'] = in_df['Return_Num']\n",
    "    df['Return_Out'] = out_df['Return_Num']\n",
    "    df['Return_Net'] = in_df['Return_Num'] - out_df['Return_Num']\n",
    "\n",
    "    df['Exmpt_In'] = in_df['Exmpt_Num']\n",
    "    df['Exmpt_Out'] = out_df['Exmpt_Num']\n",
    "    df['Exmpt_Net'] = in_df['Exmpt_Num'] - out_df['Exmpt_Num']\n",
    "    \n",
    "    \n",
    "    df['Aggr_AGI_In'] = in_df['Aggr_AGI']\n",
    "    df['Aggr_AGI_Out'] = out_df['Aggr_AGI']\n",
    "    df['Aggr_AGI_Net'] = in_df['Aggr_AGI'] - out_df['Aggr_AGI']\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "def get_all_fips(df):\n",
    "    fips = df[[0]].fillna(value='01').values + df[[1]].fillna(value='001').values\n",
    "    s = set(fips[:,0].tolist())\n",
    "    return set(map(lambda x: (x[0:2], x[2:6]), s))\n",
    "\n",
    "def load_flow_csv(file_name):\n",
    "    return  pd.read_csv(file_name,\n",
    "                         dtype={'State_Code_Dest':np.str,\n",
    "                                'County_Code_Dest':np.str,\n",
    "                                'State_Code_Origin':np.str,\n",
    "                                'County_Code_Origin':np.str,\n",
    "                                'State_Abbrv':np.str,\n",
    "                                'County_Name':np.str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtProd = pd.read_csv('../../Notes/agentProd.csv', dtype={'CUR PLAN CODE':np.str, 'MOA ST-AGT-CD':np.str,'PRIMARY ST-AGT-CD.1':np.str,'zip5':np.str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print agtProd.columns[2:13]\n",
    "agtProd[agtProd.columns[2]].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtProd[agtProd.columns[2:13]].applymap(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtProd = pd.read_csv('../../Notes/agentProd.csv', thousands=',' ,dtype={'SSN':np.str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList['AWARDS ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList[agentList['AWARDS ID'] == 110778]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fireCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2008 = [c for c in agtProd if c.endswith('2008')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fireY1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtProd[agtProd.AWARDS_ID == 110778][y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtProd[agtProd.AWARDS_ID.isnull()][agtProd.columns[2:]].sum()\n",
    "agtProd[agtProd.AWARDS_ID.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## join AGENTList with agentProd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in the agent file\n",
    "agentList = pd.read_csv('agent/agentInfo2.csv', dtype={'CUR PLAN CODE':np.str, 'MOA ST-AGT-CD':np.str,'PRIMARY ST-AGT-CD.1':np.str,'zip5':np.str},index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(agentList['AWARDS ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(agentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agtProd.drop('SSN',axis=1,inplace=True) # remove SSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList.rename(columns={'AWARDS ID':'AWARDS_ID'},inplace=True) #get joining axis to match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agentList.AWARDS_ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(agtProd.AWARDS_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.merge(agentList,agtProd,on='AWARDS_ID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.AWARDS_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volAutoCols = [c for c in df.columns if c.startswith('VOL AUTO')]\n",
    "print volAutoCols\n",
    "volAutoCols.remove('VOL AUTO 2013-11 PYTD')\n",
    "volAutoCols.remove('VOL AUTO 2014-11 YTD')\n",
    "volAutoCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAnnualColumnNames(df, cname):\n",
    "    columnList = [c for c in df.columns if c.startswith(cname)]\n",
    "    # id elements that are PYTD/YTD\n",
    "    toDropList = [c for c in columnList if c.endswith('YTD')]\n",
    "    for a in toDropList:\n",
    "        columnList.remove(a)\n",
    "    return columnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawnewAutoCols= getAnnualColumnNames(df,'AUTO RAW')\n",
    "rawnewAutoCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# consider the cases where someone changes locations\n",
    "df.AWARDS_ID.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.AWARDS_ID==119365][['APPOINT DATE','TERMINATION DATE','STATUS','zip5','PRIMARY ST-AGT-CD','VOL AUTO 2005','VOL AUTO 2008']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert TERMINATION DATE to datetime\n",
    "isActiveIDX = df[df['TERMINATION DATE'].isnull()].index\n",
    "\n",
    "print len(isActiveIDX), \" active agents\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['TERMINATION DATE'] = df['TERMINATION DATE'].apply(lambda x: pd.to_datetime(x,format='%d%b%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ended2005orLaterIDX = df[df['TERMINATION DATE'] > '2004-12-31'].index\n",
    "len(ended2005orLaterIDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keepIDX = isActiveIDX.union(ended2005orLaterIDX)\n",
    "len(keepIDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['TERMINATION DATE'].apply(lambda x: pd.to_datetime(x,format='%d%b%Y')) > '2004-12-31']['TERMINATION DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do the same for RAW New\n",
    "rawnewAutoCols = [c for c in df.columns if c.startswith('AUTO RAW')]\n",
    "print rawnewAutoCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns[200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I should go through this one and check the year with the termination date for cases with multiple listings -- also need to look at apoint date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf = df.ix[keepIDX].copy()\n",
    "print len(kdf)\n",
    "kdf.index = np.arange(0,len(kdf)) # reindex it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert appoint date to datetime\n",
    "kdf['APPOINT DATE'] = kdf['APPOINT DATE'].apply(lambda x: pd.to_datetime(x,format='%d%b%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nvc = kdf.AWARDS_ID.value_counts() # which ones are multiple valuecounts\n",
    "print len(nvc[nvc>1])\n",
    "dupAgentIDs = nvc[nvc>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawnewAutoCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearSpan1 = pd.date_range(start ='1/1/2004',end='1/1/2014',freq='A')\n",
    "print len(yearSpan1),len(rawnewAutoCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[t for t in yearSpan1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf[kdf.AWARDS_ID == 119365]['TERMINATION DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf[kdf.AWARDS_ID == 122000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[t for t in yearSpan1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf.ix[8049]['TERMINATION DATE'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dupAgentIDs = map(int,dupAgentIDs.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dupAgentIDs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf[kdf.AWARDS_ID == dupAgentIDs[5]][['APPOINT DATE','TERMINATION DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf[kdf.AWARDS_ID == dupAgentIDs[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearCols = {}\n",
    "years2 = ['2005','2006','2007','2008','2009','2010','2011','2012','2013']\n",
    "for y in years2:\n",
    "    yearCols[y]= [b for b in kdf.columns if y in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up the 2013 PYTD values\n",
    "yy = yearCols['2013']\n",
    "for a in yy:\n",
    "    print a\n",
    "    if a.endswith('PYTD'):\n",
    "        print a\n",
    "        yy.remove(a)\n",
    "    \n",
    "len(yearCols['2013']), len(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## approach to correct for duplicated/moved agents\n",
    "* assigned the columns for a given year to the corresponding dictionary `yearCol['2011']` for example\n",
    "* copy singletons to a new data frame unchanged.\n",
    "* step through the duplicated agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fullAGT = kdf[~kdf.AWARDS_ID.isin(dupAgentIDs)].copy()\n",
    "len(fullAGT), len(kdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minStart = yearSpan1[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in dupAgentIDs:\n",
    "    print a, \n",
    "    dindex = kdf[kdf.AWARDS_ID == a].index\n",
    "    for idx in dindex:\n",
    "        tdate = kdf.ix[idx]['TERMINATION DATE']\n",
    "        adate = kdf.ix[idx]['APPOINT DATE']\n",
    "        print idx, tdate, adate\n",
    "        # zero out if appoint date Year is > year\n",
    "        yrs_to_drop = [key for key in yearCols.keys() if int(key) < adate.year]\n",
    "        \n",
    "        if len(yrs_to_drop)>0:\n",
    "            print yrs_to_drop\n",
    "            for yy in yrs_to_drop:\n",
    "                #pass\n",
    "                kdf.loc[idx,yearCols[yy]]=0\n",
    "\n",
    "        # zero out if year is > TERMINATION DATE\n",
    "        tyear = tdate.year\n",
    "        if tyear > -1:\n",
    "            tyrs_to_drop = [key for key in yearCols.keys() if int(key) > tyear ]\n",
    "            if len(tyrs_to_drop)>0:\n",
    "                print \"Tyrs to drop:\", tyrs_to_drop\n",
    "                for yy in tyrs_to_drop:\n",
    "                    #pass\n",
    "                    kdf.loc[idx,yearCols[yy]]=0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf[kdf.AWARDS_ID==dupAgentIDs[8]][['APPOINT DATE','TERMINATION DATE','zip5','AUTO RAW NEW 2005','AUTO RAW NEW 2011','COUNTY','STATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf.to_csv('agent/agent_policy_amounts_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(kdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb = kdf.ix[idx][yearCols[yrs_to_drop[0]]].copy()\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf.loc[idx,yearCols[yrs_to_drop[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[key for key in yearCols.keys() if int(key)> 2006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correct_for_agent_change(df,agent_id,year):\n",
    "    # get the list of columns containing a given year\n",
    "    yearCols = [b for b in df.columns if year in b]\n",
    "    ydate = pd.to_datetime(year+'-12-31') # assign as the end of the year\n",
    "    # identify cases where the termination date is before ydate\n",
    "    # A) if year is greater than termination date reset values to zero\n",
    "    df[df.AW]\n",
    "    # B) if appoint date is greater than year reset values to zero\n",
    "    #df[yearCols] = \n",
    "    tdate = df[df.AWARDS_ID == agent_id]['TERMINATION DATE']\n",
    "    adate = df[df.AWARDS_ID == agent_id]['APPOINT DATE']\n",
    "    # flag the ones with beginning PIF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdate = kdf[kdf.AWARDS_ID == dupAgentIDs[2]]['TERMINATION DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myY = '2009'\n",
    "ydate = pd.to_datetime(myY+'-12-31')\n",
    "ydate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ydate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf[(kdf.AWARDS_ID == dupAgentIDs[1]) & (kdf['TERMINATION DATE']< ydate)][['APPOINT DATE','TERMINATION DATE','zip5','COUNTY','STATE','STATUS','AUTO RAW NEW 2011']]#y0cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for a in nvc.index[:3]:\n",
    "    print a, \n",
    "    print kdf[kdf.AWARDS_ID == int(a)][['APPOINT DATE','TERMINATION DATE','zip5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf[kdf.AWARDS_ID==119160][['APPOINT DATE', 'TERMINATION DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf.groupby('zip5').get_group('46219')[lifeCols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fireCols = getAnnualColumnNames(df,'FIRE')\n",
    "fireCols, len(fireCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lifeCols = getAnnualColumnNames(df,'LIFE')\n",
    "lifeCols, len(lifeCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "healthCols = getAnnualColumnNames(df,'HEALTH')\n",
    "#healthCols, len(healthCols)\n",
    "phoenixCols = getAnnualColumnNames(df,'PHOENIX')\n",
    "phoenixCols = phoenixCols[1:] #omit the agrement date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdf.columns[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isActive(df,date,today=pd.to_datetime('12-31-2020')):\n",
    "    #print sum(df['TERMINATION DATE'].isnull())\n",
    "    # replace null times with today\n",
    "    df['TERMINATION DATE'].fillna(today,inplace=True)\n",
    "    #print sum(df['TERMINATION DATE'].isnull())\n",
    "    nactive= len(df[(df['APPOINT DATE'] <= date) & (df['TERMINATION DATE']>date)])\n",
    "    #print nactive\n",
    "    return nactive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
